Starting State (Epoch 1, Step 0)
W = 0.23 (random)
B = -0.15 (random)
Step 1: Forward Pass (outputs = model(distances))
What happens in parallel:
For ALL 4 distances at once, calculate predictions:
Distance 1 mile: prediction = 0.23 Ã— 1 + (-0.15) = 0.08 minutes
Distance 2 miles: prediction = 0.23 Ã— 2 + (-0.15) = 0.31 minutes  
Distance 3 miles: prediction = 0.23 Ã— 3 + (-0.15) = 0.54 minutes
Distance 4 miles: prediction = 0.23 Ã— 4 + (-0.15) = 0.77 minutes
Actual times were: [6.96, 12.11, 16.77, 22.21]
These predictions are terrible! That's why we need training.

Step 2: Calculate Loss (loss = loss_function(outputs, times))
Understanding Loss (MSE - Mean Squared Error)
Formula: Average of (prediction - actual)Â²
Let's calculate for epoch 1:
Sample 1: (0.08 - 6.96)Â² = (-6.88)Â² = 47.33
Sample 2: (0.31 - 12.11)Â² = (-11.80)Â² = 139.24
Sample 3: (0.54 - 16.77)Â² = (-16.23)Â² = 263.41
Sample 4: (0.77 - 22.21)Â² = (-21.44)Â² = 459.67

MSE = (47.33 + 139.24 + 263.41 + 459.67) / 4 = 227.41
Loss = 227.41 (huge! Model is very wrong)
Why square the errors?

Makes all errors positive (can't have -5 cancel out +5)
Penalizes big mistakes heavily (error of 10 contributes 100, error of 1 contributes 1)


Step 3: Backward Pass (loss.backward())
This calculates gradients - how to adjust W and B to reduce loss.
Gradient = derivative of loss with respect to parameter
Think of it as: "If I increase W by a tiny amount, how much does loss change?"
Mathematical intuition:

If loss goes UP when W increases â†’ gradient is positive â†’ decrease W
If loss goes DOWN when W increases â†’ gradient is negative â†’ increase W

What PyTorch calculates:
gradient_W = âˆ‚Loss/âˆ‚W â‰ˆ -157.23 (loss decreases if W increases)
gradient_B = âˆ‚Loss/âˆ‚B â‰ˆ -62.89 (loss decreases if B increases)
The math behind this uses calculus (chain rule), but PyTorch does it automatically!

Step 4: Optimizer Step (optimizer.step())
Understanding SGD (Stochastic Gradient Descent)
"Gradient Descent" = follow the gradient downhill to minimize loss
"Stochastic" = use a random subset of data (though with 4 samples, we use all)
Update formula:
new_W = old_W - learning_rate Ã— gradient_W
new_B = old_B - learning_rate Ã— gradient_B
With our numbers (lr=0.01):
new_W = 0.23 - (0.01 Ã— -157.23) = 0.23 + 1.5723 = 1.8023
new_B = -0.15 - (0.01 Ã— -62.89) = -0.15 + 0.6289 = 0.4789

ðŸŽ“ Understanding Learning Rate
Learning rate (lr) = size of each step toward the minimum
Visual analogy: You're hiking down a mountain in fog
lr = 0.01 (good): Small careful steps, you reach the bottom safely
lr = 1.0 (too high): Giant leaps, you might jump over the valley and climb back up the other side
lr = 0.0001 (too low): Tiny baby steps, takes forever to get down
Example with same gradient:
gradient_W = -157.23

lr = 0.0001: W changes by 0.0001 Ã— 157.23 = 0.016 (barely moves)
lr = 0.01:   W changes by 0.01 Ã— 157.23 = 1.57 (good progress)
lr = 1.0:    W changes by 1.0 Ã— 157.23 = 157.23 (way too much!)

ðŸ”„ What Happens Over Multiple Epochs
Epoch 1:

W: 0.23 â†’ 1.80
B: -0.15 â†’ 0.48
Loss: 227.41

Epoch 2:

Forward pass with NEW W and B
Predictions are better
Loss: maybe 180
Calculate new gradients
Update again

...continues...
Epoch 50:

W: ~4.8
B: ~1.7
Loss: 0.039 (much better!)

Epoch 500:

W: 5.015
B: 1.985
Loss: 0.026 (very good!)


ðŸ“Š Parallel Processing
Everything happens in parallel on tensors:
When you do model(distances), PyTorch does:
python# Instead of:
for d in distances:
    pred = W * d + B
    
# It does (vectorized):
predictions = W * distances + B  # All at once on GPU!
This is why we use shape (4, 1) instead of 4 separate numbers - enables parallel computation.

ðŸŽ¯ Common Misconceptions Clarified
Q: Does SGD update after each sample or all 4?
A: With your code, it processes all 4, then updates. That's actually "batch gradient descent." True SGD updates after each sample. Mini-batch SGD uses small batches.
Q: Why 500 epochs?
A: Arbitrary choice. Could be 100 or 1000. You'd stop when loss plateaus (stops decreasing).
Q: What if I used lr=0.1 instead of 0.01?
A: Training might be faster but riskier - could overshoot and oscillate. lr=0.01 is conservative.

Loss = how wrong your model is (want to minimize)
Gradient = direction and magnitude to adjust parameters
Learning rate = step size for adjustments
Epoch = one complete pass through all data
Forward pass = make predictions
Backward pass = calculate gradients
Optimizer step = update parameters using gradients

